{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '.'\n",
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "with open(pickle_file, 'rb') as fileReader:\n",
    "    dataset = pickle.load(fileReader)\n",
    "train_dataset = dataset['train_dataset']\n",
    "train_labels = dataset['train_labels']\n",
    "valid_dataset = dataset['valid_dataset']\n",
    "valid_labels = dataset['valid_labels']\n",
    "test_dataset = dataset['test_dataset']\n",
    "test_labels = dataset['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_test = test_dataset.reshape(test_dataset.shape[0], 28 * 28)\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "sample_size = 50\n",
    "X_train = train_dataset[:sample_size].reshape(sample_size, 28*28)\n",
    "y_train = train_labels[:sample_size]\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208.76631331443787"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softMax(lst):\n",
    "    s = np.exp(lst).sum()\n",
    "    return [np.exp(f) / s for f in lst]\n",
    "coefs = np.ones(X_train.shape[1], X_train.dtype)\n",
    "logit = np.dot(X_train, coefs)\n",
    "logit = logit / (0.5 * np.average(logit))\n",
    "sm = softMax(logit)\n",
    "# print(np.exp(logit).sum())\n",
    "# print(logit)\n",
    "# print(sm)\n",
    "# np.sum(sm)\n",
    "s = -1 * np.sum((np.array(y_train) + np.log(np.array(sm))))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.5        -0.49607843 -0.5        ... -0.5        -0.49215686\n",
      "   -0.5       ]\n",
      "  [-0.49607843 -0.4764706  -0.5        ... -0.5        -0.47254902\n",
      "   -0.49607843]\n",
      "  [-0.49607843 -0.49607843 -0.5        ... -0.5        -0.49607843\n",
      "   -0.49607843]\n",
      "  ...\n",
      "  [-0.49607843 -0.49215686 -0.5        ... -0.5        -0.49215686\n",
      "   -0.49607843]\n",
      "  [-0.49607843 -0.4764706  -0.5        ... -0.5        -0.47254902\n",
      "   -0.49607843]\n",
      "  [-0.5        -0.49607843 -0.5        ... -0.5        -0.49607843\n",
      "   -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ...  0.4882353   0.5\n",
      "    0.1509804 ]\n",
      "  [-0.5        -0.5        -0.5        ...  0.48431373  0.14705883\n",
      "   -0.327451  ]\n",
      "  [-0.5        -0.5        -0.5        ... -0.327451   -0.5\n",
      "   -0.49607843]\n",
      "  ...\n",
      "  [-0.5        -0.4490196   0.1509804  ... -0.5        -0.5\n",
      "   -0.5       ]\n",
      "  [-0.49607843 -0.49607843 -0.49215686 ... -0.5        -0.5\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.49607843 -0.4882353  ... -0.5        -0.5\n",
      "   -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ... -0.5        -0.5\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ... -0.5        -0.5\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.5        -0.49607843 ... -0.5        -0.5\n",
      "   -0.5       ]\n",
      "  ...\n",
      "  [-0.5        -0.5        -0.5        ... -0.4882353  -0.5\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ... -0.5        -0.5\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ... -0.5        -0.5\n",
      "   -0.5       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ... -0.49215686 -0.5\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ... -0.49607843 -0.49215686\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ... -0.45686275 -0.5\n",
      "   -0.4882353 ]\n",
      "  ...\n",
      "  [-0.5        -0.5        -0.5        ...  0.4137255  -0.19019608\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ... -0.45686275 -0.5\n",
      "   -0.49607843]\n",
      "  [-0.5        -0.5        -0.5        ... -0.49607843 -0.49215686\n",
      "   -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ...  0.45686275  0.5\n",
      "    0.20980392]\n",
      "  [-0.5        -0.5        -0.5        ...  0.49607843  0.5\n",
      "    0.3156863 ]\n",
      "  [-0.5        -0.5        -0.5        ... -0.24509804 -0.26862746\n",
      "   -0.42156863]\n",
      "  ...\n",
      "  [ 0.2764706   0.5         0.5        ...  0.09215686 -0.33529413\n",
      "   -0.5       ]\n",
      "  [-0.30784315  0.327451    0.5        ... -0.5        -0.5\n",
      "   -0.5       ]\n",
      "  [-0.5        -0.44509804 -0.12352941 ... -0.4882353  -0.49215686\n",
      "   -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.4882353  ...  0.4764706   0.5\n",
      "    0.14705883]\n",
      "  [-0.5        -0.5        -0.48431373 ...  0.48431373  0.5\n",
      "   -0.01372549]\n",
      "  [-0.5        -0.5        -0.48431373 ...  0.17843138  0.18235295\n",
      "   -0.28039217]\n",
      "  ...\n",
      "  [-0.00980392  0.5         0.48431373 ... -0.4882353  -0.5\n",
      "   -0.5       ]\n",
      "  [ 0.14705883  0.5         0.4882353  ... -0.4882353  -0.5\n",
      "   -0.5       ]\n",
      "  [ 0.30392158  0.5         0.49215686 ... -0.49215686 -0.5\n",
      "   -0.5       ]]]\n"
     ]
    }
   ],
   "source": [
    "X_test = test_dataset.reshape(test_dataset.shape[0], 28 * 28)\n",
    "y_test = test_labels\n",
    "\n",
    "class AmirLogisticRegression:\n",
    "    def logit(X_train, coefs):\n",
    "        logit = np.dot(X_train, coefs)\n",
    "        return logit / (0.5 * np.average(logit))\n",
    "    def softMax(lst):\n",
    "        s = np.exp(lst).sum()\n",
    "        return [np.exp(f) / s for f in lst]\n",
    "    def crossEntropy(S,L):\n",
    "        return -1 * np.sum((np.array(y_train) + np.log(np.array(sm))))\n",
    "    def logisticRegressionPath(X_train, Y_vector, coefs, classes):\n",
    "        sy = logit(X_train, coefs)\n",
    "        sm = softMax(sy)\n",
    "        d = crossEntropy(sm, Y_vector)\n",
    "        return coefs\n",
    "    def fit(self, X_matrix, Y_vector):\n",
    "        if (len(X_matrix) != len(Y_vector)):\n",
    "            raise ValueError('sizes dont match.')\n",
    "        self._classes = np.unique(y_train) # classes = labels = possible classifications (0='A', 1='B' => y=[0,1,0,0,1], self._classes = [0,1])\n",
    "        num_classes = len(self._classes)\n",
    "        num_samples, num_features = X_Matrix.shape\n",
    "        self._coef = np.ones(X_matrix.shape[0], X_matrix.dtype) # coefficient of the features. shape of (num_featuers, 1)\n",
    "        \n",
    "        return self\n",
    "\n",
    "def test_LogisticRegression(sample_size):\n",
    "    lr = LogisticRegression()\n",
    "    X_train = train_dataset[:sample_size].reshape(sample_size, 28*28)\n",
    "    y_train = train_labels[:sample_size]\n",
    "    %time lr.fit(X_train,y_train)\n",
    "    correct = 0\n",
    "    s = lr.score(X_test,y_test)\n",
    "    print(s)\n",
    "test_LogisticRegression(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
